{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 - Model Building for Production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents\n",
    "\n",
    "<a href = \"part-1_EDA.ipynb\">Part 1 - Exploratory Data Analysis</a><br>\n",
    "\n",
    "<a href = \"part-2_data_cleaning\">Part 2 - Data Cleaning</a>\n",
    "    \n",
    "Part 3 - Production Model Building\n",
    "\n",
    "- [Summary of Steps](#Summary-of-Steps)\n",
    "- [Preprocessing](#Preprocessing)\n",
    "- [Hyperparameter Tuning](#Hyperparameter-Tuning)\n",
    "- [Model Selection](#Model-Selection)\n",
    "- [Kaggle Submission](#Kaggle-Submission)\n",
    "- [Conclusion and Discussion](#Conclusion-and-Discussion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.model_selection import cross_val_score, KFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, Lasso, LassoCV, ElasticNet, ElasticNetCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Data\n",
    "[top](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dataset\n",
    "\n",
    "ames_data_lasso = (\"datasets/final_ames.csv\")\n",
    "\n",
    "ames = pd.read_csv(ames_data_lasso)\n",
    "\n",
    "ames.drop(columns = [\"Unnamed: 0\"], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the dataset cleaned and the features chosen, a linear regression model will have to be selectedas the base for the model. There are 4 choices: Linear Regression, Lasso Regression , Ridge regression and ElasticNet regression. An additional dummy regressor was added to serve as a baseline for measurement.\n",
    "\n",
    "The data was split into training and test data sets to provide a measure of performance for each of the models, and then standard scaled. The best hyperparameters for each model were found, and all 5 models were cross validated. \n",
    "\n",
    "From the cross-validation, a Ridge Regression model with an alpha of about 48 provided the best score, and was used to generate the predictions for the Kaggle submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "[top](#Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting varibles into features and target\n",
    "\n",
    "features = list(ames.columns)\n",
    "features.remove(\"saleprice\")\n",
    "\n",
    "X = ames[features]\n",
    "y = ames[\"saleprice\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into training set and test set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "[top](#Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RidgeCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ridge alpha: 34.09285069746813\n",
      "Best ridge r2: 0.8901254491515729\n"
     ]
    }
   ],
   "source": [
    "r_alphas = np.logspace(0, 5, 200)\n",
    "rid_cv = RidgeCV(alphas=r_alphas, cv = 10)\n",
    "rid_cv = rid_cv.fit(X_train_scaled, y_train)\n",
    "\n",
    "print (f'Best ridge alpha: {rid_cv.alpha_}')\n",
    "print (f'Best ridge r2: {rid_cv.score(X_train_scaled, y_train)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Lasso alpha: 0.15000000000000002\n",
      "Best Lasso r2: 0.8902576594786166\n"
     ]
    }
   ],
   "source": [
    "l_alphas = np.arange(0.01, 0.20, 0.01)\n",
    "las_cv = LassoCV(alphas=l_alphas, cv = 10, max_iter = 5000)\n",
    "las_cv = las_cv.fit(X_train_scaled, y_train)\n",
    "\n",
    "print (f'Best Lasso alpha: {las_cv.alpha_}')\n",
    "print (f'Best Lasso r2: {las_cv.score(X_train_scaled, y_train)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ElasticNetCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Checking for best ElasticNet alpha\n",
    "\n",
    "e_alphas = np.arange(0.01, 0.20, 0.01)\n",
    "l1_ratios = np.arange(0, 1, 0.1)\n",
    "el_cv = ElasticNetCV(alphas=e_alphas, l1_ratio = l1_ratios, cv = 10, max_iter = 5000)\n",
    "el_cv = el_cv.fit(X_train_scaled, y_train)\n",
    "\n",
    "print (f'Best ElasticNet alpha: {el_cv.alpha_}')\n",
    "print (f'Best ElasticNet L1 ratio: {el_cv.l1_ratio_}')\n",
    "print (f'Best ElasticNet r2: {el_cv.score(X_train_scaled, y_train)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "[top](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling models\n",
    "lr = LinearRegression()\n",
    "rd = Ridge(alpha = rid_cv.alpha_)\n",
    "ls = Lasso(alpha = las_cv.alpha_)\n",
    "el = ElasticNet(alpha = el_cv.alpha_, l1_ratio = el_cv.l1_ratio_)\n",
    "dum = DummyRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom function for cross validation\n",
    "\n",
    "def validator(model, x_train, x_test, y_train, y_test, nfolds = 10):\n",
    "    \n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    kf = KFold(nfolds, shuffle = True, random_state = 5)\n",
    "    \n",
    "    train_rmse = np.sqrt(-cross_val_score(model, x_train, y_train, cv = kf, scoring = 'neg_mean_squared_error'))\n",
    "    train_r2 = cross_val_score(model, x_train, y_train, cv=kf)\n",
    "    \n",
    "    y_predict = model.predict(x_test)\n",
    "    \n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_predict))\n",
    "    test_r2 = model.score(x_test, y_test)\n",
    "    \n",
    "    print(f'For {model} with seen data:\\nMean RMSE: {round(train_rmse.mean(),5)},\\nMean CV r2:{round(train_r2.mean(),5)}\\n')\n",
    "    print(f'For {model} with unseen data:\\nMean RMSE: {round(test_rmse.mean(),5)},\\nMean CV r2:{round(test_r2.mean(),5)}\\n')\n",
    "    print(\"-----------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Running function on all models\n",
    "\n",
    "model_list = [dum,lr,rd,ls,el]\n",
    "\n",
    "for i in model_list:\n",
    "    validator(i, X_train_scaled,X_test_scaled, y_train,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Submission\n",
    "[top](#Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing and Cleaning Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dataset\n",
    "\n",
    "testcsv = (\"datasets/test.csv\")\n",
    "\n",
    "test = pd.read_csv(testcsv)\n",
    "\n",
    "# title cleanup\n",
    "\n",
    "def edit_title (title):\n",
    "    \n",
    "    title = (title.replace(\" \",\"_\")).lower()\n",
    "    \n",
    "    return title\n",
    "\n",
    "test.rename(columns = lambda i:edit_title(i), inplace = True)\n",
    "\n",
    "# 3 column names start with numbers. Replacing numbers with strings.\n",
    "\n",
    "test.rename(columns = {'1st_flr_sf':\"first_flr_sf\",  '2nd_flr_sf':'second_flr_sf',\"3ssn_porch\":\"threessn_porch\"}, inplace = True)\n",
    "\n",
    "# Removing unwanted columns\n",
    "\n",
    "no_data = ['id', 'pid','misc_feature', 'misc_val']\n",
    "\n",
    "l_num = [\"mas_vnr_area\", \"bsmtfin_sf_2\",\"low_qual_fin_sf\", \"bsmt_half_bath\", \"half_bath\", \n",
    "                          \"kitchen_abvgr\", \"pool_area\"]\n",
    "\n",
    "l_nom = [\"street\",\"alley\",\"land_contour\",\"condition_1\",\"condition_2\",\"roof_matl\",\"bsmtfin_type_2\",\n",
    "                         \"heating\",\"paved_drive\",\"sale_type\"]\n",
    "\n",
    "l_ord = [\"utilities\", \"land_slope\",\"exter_cond\",\"bsmt_cond\",\"central_air\", \"electrical\",\n",
    "                          \"functional\", \"garage_qual\", \"garage_cond\", \"pool_qc\"]\n",
    "\n",
    "low_cor = [\"mo_sold\",\"yr_sold\"]\n",
    "\n",
    "high_null = ['fireplace_qu','fence']\n",
    "\n",
    "comb_list = no_data+l_num+l_nom+l_ord+low_cor+high_null\n",
    "\n",
    "test.drop(columns = comb_list, inplace = True)\n",
    "\n",
    "colinear = ['exter_qual', 'kitchen_qual','garage_yr_blt','garage_cars']\n",
    "\n",
    "test.drop(columns = colinear, inplace = True)\n",
    "\n",
    "# combining different types of porch sf to a single column\n",
    "\n",
    "porch_sfs = ['open_porch_sf', 'enclosed_porch', 'threessn_porch','screen_porch']\n",
    "\n",
    "test['porch_sf'] = test[porch_sfs].sum(axis = 1)\n",
    "\n",
    "# dropping porch columns\n",
    "\n",
    "test.drop(columns = porch_sfs, inplace = True)\n",
    "\n",
    "# creating list of continuous data columns\n",
    "\n",
    "num_cols = [i for i in test.columns if test[i].dtypes == int or test[i].dtypes == float]\n",
    "\n",
    "# ms_subclass, while numerical in value, is nominal in nature. Removing it from the num_cols list.\n",
    "\n",
    "# months and years should also be classified as ordinal rather than numerical data\n",
    "\n",
    "list_nonnums = [\"ms_subclass\", \"year_built\", \"year_remod/add\"]\n",
    "\n",
    "for i in list_nonnums:\n",
    "    num_cols.remove(i)\n",
    "    \n",
    "# The remanining data had to be cross examined with the data dictionary to determine if it was nominal or ordinal.\n",
    "\n",
    "# Listing out norminal data\n",
    "\n",
    "cat_nom_cols = ['ms_subclass','ms_zoning',\n",
    " 'lot_config',\n",
    " 'neighborhood',\n",
    " 'bldg_type',\n",
    " 'house_style',\n",
    " 'roof_style',\n",
    " 'exterior_1st',\n",
    " 'exterior_2nd',\n",
    " 'mas_vnr_type',\n",
    " 'foundation',\n",
    " 'bsmtfin_type_1',\n",
    " 'garage_type']\n",
    "\n",
    "# Creating ordinal data list\n",
    "\n",
    "cat_ord_cols = [i for i in test.columns if i not in num_cols and i not in cat_nom_cols]\n",
    "\n",
    "# Changing all num_cols to floats.\n",
    "\n",
    "for i in num_cols:\n",
    "    test[i] = test[i].map(lambda x:float(x))\n",
    "\n",
    "#for the \"ms_subclass\" column, data should be strings insted of floats\n",
    "\n",
    "test[\"ms_subclass\"] = test[\"ms_subclass\"].map(lambda x:str(x))\n",
    "\n",
    "\n",
    "# mean imputation for numerical columns\n",
    "\n",
    "def mean_impute(df, col):\n",
    "    for i in col:\n",
    "        mean = df[i].mean()\n",
    "        df[i] = df[i].fillna(mean)\n",
    "        \n",
    "mean_impute(test, num_cols)\n",
    "\n",
    "# filling categorical columns with \"NA\"\n",
    "\n",
    "test[cat_nom_cols] = test[cat_nom_cols].fillna(\"NA\")\n",
    "test[cat_ord_cols] = test[cat_ord_cols].fillna(\"NA\")\n",
    "\n",
    "\n",
    "# lable encoding lot_shape\n",
    "\n",
    "lot_shape_dict = {\"NA\":0, \"Reg\":1, \"IR1\": 2, \"IR2\": 3, \"IR3\":4}\n",
    "\n",
    "# lable encoding exterqual, extercon, bsmtqual, bsmtcon, heatingqc, kitchenqual, fireplacequ, garagequal, garagecond\n",
    "# poolqc\n",
    "\n",
    "qualcon_dict = {\"Ex\":5, \"Gd\":4, \"TA\":3, \"Fa\":2, \"Po\":1, \"NA\":0}\n",
    "\n",
    "# lable encoding bsmtexposure\n",
    "\n",
    "bsmtexp_dict = {\"Gd\":4, \"Av\":3, \"Mn\":2, \"No\":1, \"NA\":0}\n",
    "\n",
    "# lable encoding garagefinish\n",
    "\n",
    "garfin_dict = {\"Fin\":3, \"RFn\":2, \"Unf\":1, \"NA\":0}\n",
    "\n",
    "# Combining dictionaries:\n",
    "\n",
    "combine_dict = {**garfin_dict,**bsmtexp_dict,**qualcon_dict,**lot_shape_dict}\n",
    "\n",
    "# applying dictionary to ordinal non numerical columns\n",
    "\n",
    "for i in cat_ord_cols:\n",
    "    if i not in list_nonnums:\n",
    "        test[i] = test[i].map(combine_dict)\n",
    "        \n",
    "# converting nominal columns to dummies\n",
    "\n",
    "dummy_noms = pd.get_dummies(test[cat_nom_cols], drop_first = True)\n",
    "\n",
    "# dropping nominal columns\n",
    "\n",
    "test.drop(columns = cat_nom_cols, inplace=True)\n",
    "\n",
    "# log transform year built, year remod\n",
    "\n",
    "def logt(df, col):\n",
    "    df[col] = np.log(df[col])\n",
    "\n",
    "for i in [\"year_built\", \"year_remod/add\"]:\n",
    "    logt (test, i)\n",
    "    \n",
    "# merging dummies back into test set\n",
    "\n",
    "final_test = test.merge(dummy_noms, left_index = True, right_index = True)\n",
    "\n",
    "# Creating empty columns for dummy features in final test that are not in the trained model\n",
    "\n",
    "for i in features:\n",
    "    if i not in final_test.columns:\n",
    "        final_test[i] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making Final Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling training and test data\n",
    "\n",
    "X_exam = final_test[features]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_e_scaled = scaler.fit_transform(X_exam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_alphas = np.logspace(0, 5, 200)\n",
    "rid_cv = RidgeCV(alphas=r_alphas, cv = 10)\n",
    "rid_cv = rid_cv.fit(X_scaled, y)\n",
    "\n",
    "print (f'Best ridge alpha: {rid_cv.alpha_}')\n",
    "print (f'Best ridge r2: {rid_cv.score(X_scaled, y)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting Ridge Regression with optimal alpha\n",
    "rd = Ridge(alpha = rid_cv.alpha_)\n",
    "rd.fit(X_scaled, y)\n",
    "rd.score(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rd.predict(X_e_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Kaggle submission file\n",
    "\n",
    "submission = pd.read_csv(testcsv)\n",
    "submission['SalePrice'] = predictions\n",
    "submission = submission[[\"Id\", \"SalePrice\"]]\n",
    "submission.to_csv('./datasets/kaggle_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion and Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final Ridge regression model has 25 Features and a mean RMSE of 23752 on unseen data. It's public and private kaggle scores were 28919.01006 and 30388.85877 respectively.\n",
    "\n",
    "\n",
    "These scores were not the lowest possible obtained(further discussed below), and suggest that the model is underfitting the test data. However, the model strikes a balance between accuracy and usability that conforms to the requirements of the client, and would be a successful back-end predictor for the interactive website as descirbed in the brief. \n",
    "\n",
    "\n",
    "There is, of course, room for further improvement in this model. \n",
    "\n",
    "\n",
    "Of great help would be the inclusion of a domain expert, i.e. an experienced property agent, for consultation. This domain expert could provide deep insights during the examination of data, as well as assist in feature engineering, providing more comprehensive and accurate results for the feature selection process. \n",
    "\n",
    "\n",
    "There are also methods for feature selection that are not limited to Linear Regression (e.g. random forests), as well as non-parametric models that might be more effective in predicting the price from the housing data.\n",
    "\n",
    "\n",
    "Worth a further mention were several other iterations of this model which resulted in lower Kaggle scores. \n",
    "\n",
    "\n",
    "A model using 90 features, with everything else unchanged, scored an average of 500 points lower over multiple attempts, hinting that 25 features might not be providing the model enough data. \n",
    "\n",
    "Another attemt was made with log-converted sales price scores which resulted in a public kaggle score of around 22700, but a public score of around 38000. The large discrepancy suggests a difference in the test data for both score sets, and the real estate company should more acutely examine their test data for discrepancies.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
