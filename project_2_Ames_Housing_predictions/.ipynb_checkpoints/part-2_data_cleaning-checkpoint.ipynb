{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Data Cleaning and Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Foreword\n",
    "--- \n",
    "\n",
    "In the previous workbook, the data was examined, and several glaring issues found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents\n",
    "\n",
    "<a href = \"part-1_EDA.ipynb\">Part 1 - Exploratory Data Analysis</a>\n",
    "    \n",
    "Part 2 - Data Cleaning\n",
    "\n",
    "- [Data Cleaning](#Data-Cleaning)\n",
    "    - [Importing and Basic Data Cleaning](#Importing-and-Basic-Data-Cleaning)\n",
    "    - [Error Correction](#Error-Correction)\n",
    "    - [Removing Unnecessary Data and Features](#Removing-Unnecessary-Data-and-Features)\n",
    "    - [Feature Engineering](#Feature-Engineering)\n",
    "    - [Creating Lists of Columns for Different Data Types](#Creating-Lists-of-Columns-for-Different-Data-Types)\n",
    "    - [Filling Null Values](#Filling-Null-Values)\n",
    "    - [Cleaning Outliers](#Cleaning-Outliers)\n",
    "    - [Encoding](#Encoding)\n",
    "    \n",
    "    \n",
    "- [Feature Selection](#Feature-Selection)\n",
    "    - [Feature Selection for Production Model](#Feature-Selection-for_Production-Model)\n",
    "    - [Feature Selection for Kaggle Model](#Feature-Selection-for-Kaggle-Model)\n",
    "    \n",
    "<a href = \"part-3_production_model_building.ipynb\">Part 3 - Production Model Building</a><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing and Basic Data Cleaning\n",
    "[top](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Lasso, LassoCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# pandas settings\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing dataset\n",
    "\n",
    "train = (\"datasets/train.csv\")\n",
    "\n",
    "ames_train = pd.read_csv(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# title cleanup\n",
    "\n",
    "def edit_title (title):\n",
    "    \n",
    "    title = (title.replace(\" \",\"_\")).lower()\n",
    "    \n",
    "    return title\n",
    "\n",
    "ames_train.rename(columns = lambda i:edit_title(i), inplace = True)\n",
    "\n",
    "# 3 column names start with numbers. Replacing numbers with strings.\n",
    "\n",
    "ames_train.rename(columns = {'1st_flr_sf':\"first_flr_sf\",  '2nd_flr_sf':'second_flr_sf',\"3ssn_porch\":\"threessn_porch\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "[top](#Contents)\n",
    "\n",
    "---\n",
    "\n",
    "Several steps were taken to clean the data.\n",
    "\n",
    "- As mentioned in the EDA, there were several discrepancies with the \"year\" columns. These columns were further examined, and the following corrections were made:\n",
    "    - any house with a garage year built before the year built or after the year sold was imputed with the year built and year sold respectively.\n",
    "    - the same treatment was done to the \"year_remod/add\" column.\n",
    "    - finally, any house sold before it was built had the \"year_built\" value changed to the \"yr sold\" value.\n",
    "    - This left one discrepancy, which was manually handled\n",
    "  \n",
    "  \n",
    "- The data dictionary that came with the dataset recommended dropping any house whose \"gr_living_area\" was above 4000, as they were outliers. This was done.\n",
    "\n",
    "\n",
    "- 34 columns were removed for either containing no useful information or not enough variance for a model to use for making predictions.\n",
    "\n",
    "\n",
    "- Of the features remaining, several were features were found to be colinear and removed ('exter_qual', 'kitchen_qual','garage_yr_blt','garage_cars')\n",
    "\n",
    "\n",
    "- A further examination of the rest of the features revealed that the null valuescan be interpreted as a lack of that feature, and thus should be replaced by either \"0\" or \"NA\" as required.\n",
    "    - However, there were discrepancies observed in the bsmt_exposure,bsmt_qual and bsmtfin_type_1 null value counts.\n",
    "    - A similar discrepancy was also observed in the garage type and garage finish null value count.\n",
    "    - These discrepancies were imputed with mean or mode values as appropriate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A look through the dataset revealed several errors with the columns containing years.\n",
    "\n",
    "check1 = ames_train[(ames_train[\"garage_yr_blt\"] < ames_train[\"year_built\"]) | (ames_train[\"garage_yr_blt\"] > ames_train[\"yr_sold\"])]\n",
    "check2 = ames_train[(ames_train[\"year_remod/add\"] < ames_train[\"year_built\"]) | (ames_train[\"year_remod/add\"] > ames_train[\"yr_sold\"]) ]    \n",
    "check3 = ames_train[(ames_train[\"year_built\"] > ames_train[\"yr_sold\"])] \n",
    "\n",
    "# Correcting for errors\n",
    "\n",
    "for i in check3.index:\n",
    "    ames_train.at[i, \"year_built\"] = ames_train.at[i, \"yr_sold\"]\n",
    "\n",
    "for i in check1.index:\n",
    "    ames_train.at[i, \"garage_yr_blt\"] = ames_train.at[i, \"year_built\"]\n",
    "    \n",
    "for i in check2.index:\n",
    "    ames_train.at[i, \"year_remod/add\"] = ames_train.at[i, \"year_built\"]\n",
    "    \n",
    "# manually correcting the remaining row\n",
    "\n",
    "ames_train.at[1885, \"yr_sold\"] = 2008\n",
    "\n",
    "# filling empty garage_yr_blt with year_built\n",
    "ames_train[\"garage_yr_blt\"].fillna(ames_train[\"year_built\"], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Unnecessary Data and Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as recommended by data dict\n",
    "\n",
    "outliers = ames_train[ames_train[\"gr_liv_area\"]>4000].index\n",
    "\n",
    "ames_train.drop(outliers, errors='ignore', axis=0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_data = ['id', 'pid','misc_feature', 'misc_val']\n",
    "\n",
    "l_num = [\"mas_vnr_area\", \"bsmtfin_sf_2\",\"low_qual_fin_sf\", \"bsmt_half_bath\", \"half_bath\", \n",
    "                          \"kitchen_abvgr\"]\n",
    "\n",
    "#, \"pool_area\"\n",
    "\n",
    "l_nom = [\"street\",\"alley\",\"land_contour\",\"condition_1\",\"condition_2\",\"roof_matl\",\"bsmtfin_type_2\",\n",
    "                         \"heating\",\"paved_drive\",\"sale_type\"]\n",
    "\n",
    "l_ord = [\"utilities\", \"land_slope\",\"exter_cond\",\"bsmt_cond\",\"central_air\", \"electrical\",\n",
    "                          \"functional\", \"garage_qual\", \"garage_cond\", \"pool_qc\"]\n",
    "\n",
    "low_cor = [\"mo_sold\",\"yr_sold\"]\n",
    "\n",
    "high_null = ['fireplace_qu','fence']\n",
    "\n",
    "comb_list = no_data+l_num+l_nom+l_ord+low_cor+high_null\n",
    "\n",
    "ames_train.drop(columns = comb_list, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing colinear features\n",
    "\n",
    "colinear = ['exter_qual', 'kitchen_qual','garage_yr_blt','garage_cars']\n",
    "\n",
    "ames_train.drop(columns = colinear, inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining different types of porch sf to a single column\n",
    "\n",
    "porch_sfs = ['open_porch_sf', 'enclosed_porch', 'threessn_porch','screen_porch']\n",
    "\n",
    "ames_train['porch_sf'] = ames_train[porch_sfs].sum(axis = 1)\n",
    "\n",
    "# dropping porch columns\n",
    "\n",
    "ames_train.drop(columns = porch_sfs, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log transform year built, year remod and saleprice\n",
    "\n",
    "def logt(df, col):\n",
    "    df[col] = np.log(df[col])\n",
    "\n",
    "for i in [\"year_built\", \"year_remod/add\"]:\n",
    "    logt (ames_train, i)\n",
    "    \n",
    "#logt (ames_train, 'saleprice')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Lists of Columns for Different Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating list of continuous data columns\n",
    "\n",
    "num_cols = [i for i in ames_train.columns if ames_train[i].dtypes == int or ames_train[i].dtypes == float]\n",
    "\n",
    "# ms_subclass, while numerical in value, is nominal in nature. Removing it from the num_cols list.\n",
    "\n",
    "# months and years should also be classified as ordinal rather than numerical data\n",
    "\n",
    "list_nonnums = [\"ms_subclass\", \"year_built\", \"year_remod/add\"]\n",
    "\n",
    "for i in list_nonnums:\n",
    "    num_cols.remove(i)\n",
    "    \n",
    "# The remanining data had to be cross examined with the data dictionary to determine if it was nominal or ordinal.\n",
    "\n",
    "# Listing out norminal data\n",
    "\n",
    "cat_nom_cols = ['ms_subclass','ms_zoning',\n",
    " 'lot_config',\n",
    " 'neighborhood',\n",
    " 'bldg_type',\n",
    " 'house_style',\n",
    " 'roof_style',\n",
    " 'exterior_1st',\n",
    " 'exterior_2nd',\n",
    " 'mas_vnr_type',\n",
    " 'foundation',\n",
    " 'bsmtfin_type_1',\n",
    " 'garage_type']\n",
    "\n",
    "# Creating ordinal data list\n",
    "\n",
    "cat_ord_cols = [i for i in ames_train.columns if i not in num_cols and i not in cat_nom_cols]\n",
    "\n",
    "# Changing all num_cols to floats.\n",
    "\n",
    "for i in num_cols:\n",
    "    ames_train[i] = ames_train[i].map(lambda x:float(x))\n",
    "\n",
    "#for the \"ms_subclass\" column, data should be strings insted of floats\n",
    "\n",
    "ames_train[\"ms_subclass\"] = ames_train[\"ms_subclass\"].map(lambda x:str(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing columns with null values\n",
    "\n",
    "null_frame = ames_train.isnull().sum().sort_values(ascending=False).to_frame().rename(columns={0:'nulls'})\n",
    "\n",
    "null_frame[null_frame[\"nulls\"]>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols with < 10 missing value are all numerical. using mean impute.\n",
    "\n",
    "def mean_impute(df, col):\n",
    "    for i in col:\n",
    "        mean = df[i].mean()\n",
    "        df[i] = df[i].fillna(mean)\n",
    "    \n",
    "mean_impute(ames_train, ['total_bsmt_sf', 'garage_area','bsmtfin_sf_1','bsmt_unf_sf','bsmt_full_bath'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the rest of the columns, null values can be interpreted as a lack of that feature.\n",
    "\n",
    "# however, there are 3 bsmt_exposure null values more than bsmt_qual or bsmtfin_type_1.\n",
    "\n",
    "bsmt_mis = ames_train[ames_train['bsmt_exposure'].isnull() & ames_train['bsmt_qual'].notnull()]\n",
    "\n",
    "bsmt_mis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in bsmt_mis.index:\n",
    "    ames_train.at[i, \"bsmt_exposure\"] = ames_train['bsmt_exposure'].mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there is also  garage type and garage finish\n",
    "garage_mis = ames_train[ames_train['garage_finish'].isnull() & ames_train['garage_type'].notnull()]\n",
    "\n",
    "garage_mis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ames_train.at[garage_mis.index, 'garage_finish'] = ames_train['garage_finish'].mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the rest of the columns, null values can be interpreted as a lack of that feature.\n",
    "# filling columns with \"NA\" or \"0\" as appropriate\n",
    "\n",
    "ames_train[cat_nom_cols] = ames_train[cat_nom_cols].fillna(\"NA\")\n",
    "ames_train[cat_ord_cols] = ames_train[cat_ord_cols].fillna(\"NA\")\n",
    "ames_train[num_cols] = ames_train[num_cols].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom function that removes outliers based on IQR limits\n",
    "\n",
    "def IQR_rule(dataset, column, off = \"both\"):\n",
    "    \n",
    "    error = 0\n",
    "    \n",
    "#    p25 = np.percentile(dataset[column], 25)\n",
    "#    p75 = np.percentile(dataset[column], 75)\n",
    "    \n",
    "#    IQR = p75-p25\n",
    "    \n",
    "#    botlim = p25 - IQR*1.5\n",
    "#    toplim = p75 + IQR*1.5\n",
    "    \n",
    "    botlim = np.percentile(dataset[column], 1)\n",
    "    toplim = np.percentile(dataset[column], 99)\n",
    "    \n",
    "    if off == \"both\":\n",
    "        outliers = dataset[(dataset[column] < botlim) | (dataset[column] > toplim)]\n",
    "    elif off == \"top\":\n",
    "        outliers = dataset[(dataset[column] > toplim)]\n",
    "    elif off == \"bot\":\n",
    "        outliers = dataset[(dataset[column] < botlim)]\n",
    "    else:\n",
    "        error = 1\n",
    "    \n",
    "    \n",
    "    if error != 1:\n",
    "        \n",
    "        #mean = np.percentile(dataset[column], 50)\n",
    "        #outliers.apply(lambda i:mean)\n",
    "        \n",
    "        #print(f'for the column {column}, {len(outliers)} rows were replaced')\n",
    "                            \n",
    "        dataset.drop(outliers.index, errors='ignore', axis=0, inplace = True)\n",
    "        print(f'for the column {column}, {len(outliers)} rows were dropped')\n",
    "    \n",
    "    else:\n",
    "        print (\"error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in num_cols:\n",
    "#    IQR_rule(ames_train, i)\n",
    "\n",
    "IQR_rule(ames_train, 'saleprice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lot_out = ames_train[ames_train['lot_frontage'] > 300]\n",
    "lota_out = ames_train[ames_train['lot_area'] > 100000]\n",
    "wood_out = ames_train[ames_train['wood_deck_sf'] > 1250]\n",
    "porch_out = ames_train[ames_train['porch_sf'] > 600]\n",
    "\n",
    "ames_train.drop(lot_out.index, errors='ignore', axis=0, inplace = True)\n",
    "ames_train.drop(lota_out.index, errors='ignore', axis=0, inplace = True)\n",
    "ames_train.drop(wood_out.index, errors='ignore', axis=0, inplace = True)\n",
    "ames_train.drop(porch_out.index, errors='ignore', axis=0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lable encoding lot_shape\n",
    "\n",
    "lot_shape_dict = {\"NA\":0, \"Reg\":1, \"IR1\": 2, \"IR2\": 3, \"IR3\":4}\n",
    "\n",
    "# lable encoding exterqual, extercon, bsmtqual, bsmtcon, heatingqc, kitchenqual, fireplacequ, garagequal, garagecond\n",
    "# poolqc\n",
    "\n",
    "qualcon_dict = {\"Ex\":5, \"Gd\":4, \"TA\":3, \"Fa\":2, \"Po\":1, \"NA\":0}\n",
    "\n",
    "# lable encoding bsmtexposure\n",
    "\n",
    "bsmtexp_dict = {\"Gd\":4, \"Av\":3, \"Mn\":2, \"No\":1, \"NA\":0}\n",
    "\n",
    "# lable encoding garagefinish\n",
    "\n",
    "garfin_dict = {\"Fin\":3, \"RFn\":2, \"Unf\":1, \"NA\":0}\n",
    "\n",
    "# Combining dictionaries:\n",
    "\n",
    "combine_dict = {**garfin_dict,**bsmtexp_dict,**qualcon_dict,**lot_shape_dict}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying dictionary to ordinal non numerical columns\n",
    "\n",
    "for i in cat_ord_cols:\n",
    "    if i not in list_nonnums:\n",
    "        ames_train[i] = ames_train[i].map(combine_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting nominal columns to dummies\n",
    "\n",
    "dummy_noms = pd.get_dummies(ames_train[cat_nom_cols], drop_first = True)\n",
    "\n",
    "# dropping nominal columns\n",
    "\n",
    "ames_train.drop(columns = cat_nom_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ames = ames_train.merge(dummy_noms, left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ames.to_csv('datasets/final_ames.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ames.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "[top](#Contents)\n",
    "\n",
    "---\n",
    "An initial round of feature selection was made via RFECV, which revealed that the top performing model would need to incorporate 90 features. This did not fit the client's requirements, and a second round of feature selection was conducted where the features were selected via incresing the penalty of lasso regression until only 25 features remained. These selected features were cross-checked against a set of 25 features selected by RFE using linear regression, and found to be the same.\n",
    "\n",
    "For the sake of completeness, models were built on both the full 90 features, as well as the reduced 25 features, and will be examined in the following workbooks\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As per convention, splitting varibles into features and target\n",
    "\n",
    "features = list(final_ames.columns)\n",
    "features.remove(\"saleprice\")\n",
    "\n",
    "X = final_ames[features]\n",
    "y = final_ames[\"saleprice\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scaling data\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection for Kaggle Model\n",
    "[top](#Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RFE Feature Selection for Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for best alpha\n",
    "\n",
    "l_alphas = np.arange(0.01, 0.20, 0.01)\n",
    "las_cv = LassoCV(alphas=l_alphas, cv = 5, max_iter = 50000)\n",
    "las_cv = las_cv.fit(X_scaled, y)\n",
    "\n",
    "print (f'Best Lasso alpha: {las_cv.alpha_}')\n",
    "print (f'Best Lasso r2: {las_cv.score(X_scaled, y)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = Lasso(alpha = las_cv.alpha_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Custom function to show best no of features\n",
    "\n",
    "def rfe_cv(model, X, y):\n",
    "    rfecv = RFECV(ls, scoring = \"neg_mean_squared_error\" )\n",
    "    rfecv.fit(X,y)\n",
    "    no_of_features = rfecv.support_.sum()\n",
    "    print (f'{model} best no. of features is {no_of_features}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe_cv(ls, X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfe_list(model, no_of_features):\n",
    "    rfe = RFE(model, n_features_to_select=no_of_features, verbose =3 )\n",
    "    rfe.fit(X_scaled,y)\n",
    "    cols = list(X.columns)\n",
    "    temp = pd.Series(rfe.support_,index = cols)\n",
    "    selected_features_rfe = temp[temp==True].index\n",
    "    return [selected_features_rfe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe_selected = rfe_list(ls, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe_list = []\n",
    "\n",
    "for i in rfe_selected[0]:\n",
    "    rfe_list.append(i)\n",
    "    \n",
    "rfe_list += [\"saleprice\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ames[rfe_list].to_csv('datasets/kaggle/final_ames_rfe.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection for Production Model\n",
    "[top](#Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso Regression as Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As this is a production model, objective is to cut the number of features down to 30\n",
    "\n",
    "# to get 30 features, the alpha was iteratively increased until 25 features remained\n",
    "\n",
    "ls = Lasso(alpha = 0.015)\n",
    "ls.fit(X_scaled, y)\n",
    "ls_coef = pd.DataFrame(np.abs(ls.coef_), index = X.columns)\n",
    "ls_coef.rename(columns = {0:\"coef\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_selection = ls_coef.sort_values(\"coef\" ,ascending = False)\n",
    "ls_selection = ls_selection[ls_selection[\"coef\"] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_selection.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_sel_list = list(ls_selection.index) + [\"saleprice\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ames_lassoed = final_ames[ls_sel_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ames_lassoed.to_csv('datasets/production/final_ames.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RFE Feature Selection For Production Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfe_list(model, no_of_features):\n",
    "    rfe = RFE(model, n_features_to_select=no_of_features, verbose =3 )\n",
    "    rfe.fit(X_scaled,y)\n",
    "    cols = list(X.columns)\n",
    "    temp = pd.Series(rfe.support_,index = cols)\n",
    "    selected_features_rfe = temp[temp==True].index\n",
    "    return [selected_features_rfe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe_selected = rfe_list(lr, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe_list = []\n",
    "\n",
    "for i in rfe_selected[0]:\n",
    "    rfe_list.append(i)\n",
    "    \n",
    "rfe_list += [\"saleprice\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in rfe_list:\n",
    "    if i not in ls_sel_list:\n",
    "        print (i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
