{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.feature_selection import RFE, SelectFromModel\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.model_selection import cross_val_score, KFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV,Lasso, LassoCV, LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "\n",
    "# pandas settings\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "# seaborn settings\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ames_cleaned = (\"datasets/final_ames.csv\")\n",
    "\n",
    "ames = pd.read_csv(ames_cleaned)\n",
    "\n",
    "ames.drop(columns = [\"Unnamed: 0\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "saleprice               0\n",
       "heating_qc              0\n",
       "garage_area             0\n",
       "garage_finish           0\n",
       "fireplaces              0\n",
       "totrms_abvgrd           0\n",
       "bedroom_abvgr           0\n",
       "gr_liv_area             0\n",
       "second_flr_sf           0\n",
       "first_flr_sf            0\n",
       "total_bsmt_sf           0\n",
       "garage_type_NA          0\n",
       "bsmt_unf_sf             0\n",
       "bsmtfin_sf_1            0\n",
       "bsmt_exposure           0\n",
       "bsmt_qual               0\n",
       "year_remod/add          0\n",
       "year_built              0\n",
       "overall_cond            0\n",
       "overall_qual            0\n",
       "ms_subclass_20          0\n",
       "ms_subclass_30          0\n",
       "ms_subclass_50          0\n",
       "ms_subclass_60          0\n",
       "bsmtfin_type_1_NA       0\n",
       "bsmtfin_type_1_GLQ      0\n",
       "foundation_PConc        0\n",
       "exterior_2nd_MetalSd    0\n",
       "exterior_2nd_CmentBd    0\n",
       "exterior_1st_MetalSd    0\n",
       "exterior_1st_CemntBd    0\n",
       "exterior_1st_BrkFace    0\n",
       "house_style_2Story      0\n",
       "neighborhood_Somerst    0\n",
       "neighborhood_NridgHt    0\n",
       "neighborhood_NoRidge    0\n",
       "neighborhood_GrnHill    0\n",
       "neighborhood_Crawfor    0\n",
       "ms_zoning_RL            0\n",
       "ms_zoning_FV            0\n",
       "ms_subclass_70          0\n",
       "lot_area                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ames.isnull().sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(ames.columns)\n",
    "features.remove(\"saleprice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ames[features]\n",
    "y = ames[[\"saleprice\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1170, 41)\n",
      "(502, 41)\n",
      "(1170, 1)\n",
      "(502, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ridge alpha: 19.116440753857027\n",
      "Best ridge r2: 0.9084613484651742\n"
     ]
    }
   ],
   "source": [
    "r_alphas = np.logspace(0, 5, 200)\n",
    "rid_cv = RidgeCV(alphas=r_alphas, cv = 5)\n",
    "rid_cv = rid_cv.fit(X_train_scaled, y_train)\n",
    "\n",
    "print (f'Best ridge alpha: {rid_cv.alpha_}')\n",
    "print (f'Best ridge r2: {rid_cv.score(X_train_scaled, y_train)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Lasso alpha: 0.19\n",
      "Best Lasso r2: 0.9087721632851198\n"
     ]
    }
   ],
   "source": [
    "y_rav = y_train.values.ravel()\n",
    "\n",
    "l_alphas = np.arange(0.01, 0.20, 0.01)\n",
    "las_cv = LassoCV(alphas=l_alphas, cv = 5, max_iter = 50000)\n",
    "las_cv = las_cv.fit(X_train_scaled, y_rav)\n",
    "\n",
    "print (f'Best Lasso alpha: {las_cv.alpha_}')\n",
    "print (f'Best Lasso r2: {las_cv.score(X_train_scaled, y_rav)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate\n",
    "lr = LinearRegression()\n",
    "rd = Ridge(alpha = rid_cv.alpha_)\n",
    "ls = Lasso(alpha = las_cv.alpha_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validator(model, x, y, nfolds = 5):\n",
    "    \n",
    "    kf = KFold(nfolds, shuffle = True, random_state = 5)\n",
    "    \n",
    "    rmse = np.sqrt(-cross_val_score(model, x, y, cv = kf, scoring = 'neg_mean_squared_error'))\n",
    "    r2 = cross_val_score(model, x, y, cv=kf)\n",
    "    \n",
    "    return f'mean RMSE: {round(rmse.mean(),5)},  mean CV r2: {round(r2.mean(),5)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mean RMSE: 54893.05087,  mean CV r2: -0.00534'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dum = DummyRegressor()\n",
    "validator(dum, X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mean RMSE: 17460.69859,  mean CV r2: 0.89788'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validator(lr, X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mean RMSE: 17417.45479,  mean CV r2: 0.89837'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validator(rd, X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mean RMSE: 17469.34127,  mean CV r2: 0.89778'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validator(ls, X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse (y_t, y_p):\n",
    "    return np.sqrt(mean_squared_error(y_t, y_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "rd = Ridge(alpha = rid_cv.alpha_)\n",
    "ls = Lasso(alpha = las_cv.alpha_)\n",
    "dum = DummyRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dum score:-0.0009757460356012437\n",
      " dum rmse: 53119.18352916961\n",
      " lr score: 0.8818271804845101\n",
      " lr rmse: 18251.493689745574\n",
      " rd score: 0.8819603720471835\n",
      " rd rmse: 18241.205239591898\n",
      " ls score: 0.881830965932763\n",
      " ls rmse: 18251.201360940664\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dum = dum.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_predict = dum.predict(X_test_scaled)\n",
    "\n",
    "print (f' dum score:{(dum.score(X_test_scaled, y_test))}')\n",
    "print (f' dum rmse: {(rmse(y_test, y_predict))}')\n",
    "\n",
    "#-----\n",
    "\n",
    "lr = lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_predict = lr.predict(X_test_scaled)\n",
    "\n",
    "print (f' lr score: {(lr.score(X_test_scaled, y_test))}')\n",
    "print (f' lr rmse: {(rmse(y_test, y_predict))}')\n",
    "\n",
    "\n",
    "#------\n",
    "\n",
    "rd = rd.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_predict = rd.predict(X_test_scaled)\n",
    "\n",
    "print (f' rd score: {(rd.score(X_test_scaled, y_test))}')\n",
    "print (f' rd rmse: {(rmse(y_test, y_predict))}')\n",
    "\n",
    "#------\n",
    "\n",
    "ls = ls.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_predict = ls.predict(X_test_scaled)\n",
    "\n",
    "print (f' ls score: {(ls.score(X_test_scaled, y_test))}')\n",
    "print (f' ls rmse: {(rmse(y_test, y_predict))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " lr score: 0.8818271804845101\n",
    " lr rmse: 18251.493689745574\n",
    " rd score: 0.8819603720471835\n",
    " rd rmse: 18241.205239591898\n",
    " ls score: 0.881830965932763\n",
    " ls rmse: 18251.201360940664\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing against kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "testcsv = (\"datasets/test.csv\")\n",
    "\n",
    "test = pd.read_csv(testcsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# title cleanup\n",
    "\n",
    "def edit_title (title):\n",
    "    \n",
    "    title = (title.replace(\" \",\"_\")).lower()\n",
    "    \n",
    "    return title\n",
    "\n",
    "test.rename(columns = lambda i:edit_title(i), inplace = True)\n",
    "\n",
    "# 3 column names start with numbers. Replacing numbers with strings.\n",
    "\n",
    "test.rename(columns = {'1st_flr_sf':\"first_flr_sf\",  '2nd_flr_sf':'second_flr_sf',\"3ssn_porch\":\"threessn_porch\"}, inplace = True)\n",
    "\n",
    "# Removing unwanted columns\n",
    "\n",
    "no_data = ['id', 'pid','misc_feature', 'misc_val']\n",
    "\n",
    "l_num = [\"mas_vnr_area\", \"bsmtfin_sf_2\",\"low_qual_fin_sf\", \"bsmt_half_bath\", \"half_bath\", \n",
    "                          \"kitchen_abvgr\", \"pool_area\"]\n",
    "\n",
    "l_nom = [\"street\",\"alley\",\"land_contour\",\"condition_1\",\"condition_2\",\"roof_matl\",\"bsmtfin_type_2\",\n",
    "                         \"heating\",\"paved_drive\",\"sale_type\"]\n",
    "\n",
    "l_ord = [\"utilities\", \"land_slope\",\"exter_cond\",\"bsmt_cond\",\"central_air\", \"electrical\",\n",
    "                          \"functional\", \"garage_qual\", \"garage_cond\", \"pool_qc\"]\n",
    "\n",
    "low_cor = [\"mo_sold\",\"yr_sold\"]\n",
    "\n",
    "high_null = ['fireplace_qu','fence']\n",
    "\n",
    "comb_list = no_data+l_num+l_nom+l_ord+low_cor+high_null\n",
    "\n",
    "test.drop(columns = comb_list, inplace = True)\n",
    "\n",
    "colinear = ['exter_qual', 'kitchen_qual','garage_yr_blt','garage_cars']\n",
    "\n",
    "test.drop(columns = colinear, inplace = True)\n",
    "\n",
    "# combining different types of porch sf to a single column\n",
    "\n",
    "porch_sfs = ['open_porch_sf', 'enclosed_porch', 'threessn_porch','screen_porch']\n",
    "\n",
    "test['porch_sf'] = test[porch_sfs].sum(axis = 1)\n",
    "\n",
    "# dropping porch columns\n",
    "\n",
    "test.drop(columns = porch_sfs, inplace = True)\n",
    "\n",
    "# creating list of continuous data columns\n",
    "\n",
    "num_cols = [i for i in test.columns if test[i].dtypes == int or test[i].dtypes == float]\n",
    "\n",
    "# ms_subclass, while numerical in value, is nominal in nature. Removing it from the num_cols list.\n",
    "\n",
    "# months and years should also be classified as ordinal rather than numerical data\n",
    "\n",
    "list_nonnums = [\"ms_subclass\", \"year_built\", \"year_remod/add\"]\n",
    "\n",
    "for i in list_nonnums:\n",
    "    num_cols.remove(i)\n",
    "    \n",
    "# The remanining data had to be cross examined with the data dictionary to determine if it was nominal or ordinal.\n",
    "\n",
    "# Listing out norminal data\n",
    "\n",
    "cat_nom_cols = ['ms_subclass','ms_zoning',\n",
    " 'lot_config',\n",
    " 'neighborhood',\n",
    " 'bldg_type',\n",
    " 'house_style',\n",
    " 'roof_style',\n",
    " 'exterior_1st',\n",
    " 'exterior_2nd',\n",
    " 'mas_vnr_type',\n",
    " 'foundation',\n",
    " 'bsmtfin_type_1',\n",
    " 'garage_type']\n",
    "\n",
    "# Creating ordinal data list\n",
    "\n",
    "cat_ord_cols = [i for i in test.columns if i not in num_cols and i not in cat_nom_cols]\n",
    "\n",
    "# Changing all num_cols to floats.\n",
    "\n",
    "for i in num_cols:\n",
    "    test[i] = test[i].map(lambda x:float(x))\n",
    "\n",
    "#for the \"ms_subclass\" column, data should be strings insted of floats\n",
    "\n",
    "test[\"ms_subclass\"] = test[\"ms_subclass\"].map(lambda x:str(x))\n",
    "\n",
    "# filling columns with \"NA\" or \"0\" as appropriate\n",
    "\n",
    "test[cat_nom_cols] = test[cat_nom_cols].fillna(\"NA\")\n",
    "test[cat_ord_cols] = test[cat_ord_cols].fillna(\"NA\")\n",
    "test[num_cols] = test[num_cols].fillna(0)\n",
    "\n",
    "# encoding\n",
    "\n",
    "# lable encoding lot_shape\n",
    "\n",
    "lot_shape_dict = {\"NA\":0, \"Reg\":1, \"IR1\": 2, \"IR2\": 3, \"IR3\":4}\n",
    "\n",
    "# lable encoding exterqual, extercon, bsmtqual, bsmtcon, heatingqc, kitchenqual, fireplacequ, garagequal, garagecond\n",
    "# poolqc\n",
    "\n",
    "qualcon_dict = {\"Ex\":5, \"Gd\":4, \"TA\":3, \"Fa\":2, \"Po\":1, \"NA\":0}\n",
    "\n",
    "# lable encoding bsmtexposure\n",
    "\n",
    "bsmtexp_dict = {\"Gd\":4, \"Av\":3, \"Mn\":2, \"No\":1, \"NA\":0}\n",
    "\n",
    "# lable encoding garagefinish\n",
    "\n",
    "garfin_dict = {\"Fin\":3, \"RFn\":2, \"Unf\":1, \"NA\":0}\n",
    "\n",
    "# Combining dictionaries:\n",
    "\n",
    "combine_dict = {**garfin_dict,**bsmtexp_dict,**qualcon_dict,**lot_shape_dict}\n",
    "\n",
    "# applying dictionary to ordinal non numerical columns\n",
    "\n",
    "for i in cat_ord_cols:\n",
    "    if i not in list_nonnums:\n",
    "        test[i] = test[i].map(combine_dict)\n",
    "        \n",
    "# converting nominal columns to dummies\n",
    "\n",
    "dummy_noms = pd.get_dummies(test[cat_nom_cols], drop_first = True)\n",
    "\n",
    "# dropping nominal columns\n",
    "\n",
    "test.drop(columns = cat_nom_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging \n",
    "\n",
    "final_test = test.merge(dummy_noms, left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in features:\n",
    "    if i not in final_test.columns:\n",
    "        final_test[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_exam = final_test[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "y_scaled = scaler.fit_transform(y)\n",
    "X_e_scaled = scaler.fit_transform(X_exam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9034360689590297"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls = ls.fit(X_scaled, y)\n",
    "\n",
    "ls.score(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = ls.predict(X_e_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(testcsv)\n",
    "\n",
    "submission['SalePrice'] = predictions\n",
    "submission = submission[[\"Id\", \"SalePrice\"]]\n",
    "submission.to_csv('./datasets/kaggle_submission9.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
