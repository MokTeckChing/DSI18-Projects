{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# pandas settings\n",
    "pd.set_option('display.max_rows', 300)\n",
    "pd.set_option('display.max_columns', 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 - Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents\n",
    "\n",
    "<a href = \"part-1_reddit_scraper.ipynb\">Part 1 - Reddit Scraper</a>\n",
    "\n",
    "\n",
    "<a href = \"part-2_eda_and_data_cleaning.ipynb\">Part 2 - EDA and Data Cleaning</a><br>\n",
    "\n",
    "\n",
    "Part 3 - Model Building\n",
    "\n",
    "\n",
    "- [Preprocessing Data for Modeling](#Preprocessing-Data-for-Modeling)\n",
    "\n",
    "\n",
    "- [Model Selection](#Model-Selection)\n",
    "    - [Dictionary and Confusion Matrix Creation](#Dictionary-and-Confusion-Matrix-Creation)\n",
    "    - [Testing Different Models](#Testing-Different-Models)\n",
    "    \n",
    "\n",
    "- [Model Optimisation](#Model-Optimisation)\n",
    "\n",
    "\n",
    "- [Discussion](#Discussion)\n",
    "    - [Extracing Feature Importance](#Extracing-Feature-Importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data for Modeling\n",
    "[top](#Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As is the case for all modeling, the data was first imported and the target and features seperated. A train-test-split was then performed on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing data\n",
    "\n",
    "data = pd.read_csv(\"data/final_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the features and target\n",
    "\n",
    "features = list(data.columns)\n",
    "features.remove('subreddit')\n",
    "\n",
    "X = data[features]\n",
    "y = data['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state=25,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "[top](#Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three different models were examined as classifiers: Multinomial Naive Bayes, K-nearest-neighbords and Random Forests. To give a better gauge of accuracy, a GridSearchCV was ran with basic parameters to provide some minor optimization for all three models. \n",
    "\n",
    "The results show that the the RandomForest Classifier (train score = 0.76, test score = 0.71) outperformed the K-Nearest-Neighbors classifier (train score = 0.70, test score = 0.52) by a wide margin. The RandomForest Classifier equalled the Multinomal Naive Bayes Classifier (train score = 0.77, test score = 0.66) in the training data, but was superior in generalizing for the test data. \n",
    "\n",
    "This can also be observed in the confusion matrices for the classifiers, where the RandomForest confusion matrix showed less false positives and false negatives as compared to the other two classifiers.\n",
    "\n",
    "Consequently, the RandomForest Classifier was chosen for further optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary and Confusion Matrix Creation\n",
    "[top](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dictionary of models to test\n",
    "\n",
    "clas_dict = {\"nb\": MultinomialNB(),\n",
    "             \"knc\": KNeighborsClassifier(),\n",
    "             \"rf\": RandomForestClassifier()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random state set to provide similar results\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "# creating basic parameters for a GridSearch to search through\n",
    "\n",
    "clas_param = {    \n",
    "            \"nb\" :{\n",
    "                'alpha': np.linspace(0.01,0.1,10),\n",
    "                  },\n",
    "    \n",
    "            \"knc\": {\n",
    "                'leaf_size': list(range(1,5)),\n",
    "                'n_neighbors': list(range(1,5)),\n",
    "                'p': [1,2],\n",
    "                   },\n",
    "    \n",
    "            \"rf\": {\n",
    "                'n_estimators': [100,150,200],\n",
    "                'max_depth': [None, 1, 2, 3],\n",
    "                'random_state': [random_state]\n",
    "                  },\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display a confusion matrix\n",
    "\n",
    "def con_matrix(y_test, predictions):\n",
    "        \n",
    "    confusion_matrix(y_test, predictions)\n",
    "        \n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()\n",
    "        \n",
    "    return print(f'True Negatives: {tn}\\nFalse Positives: {fp}\\nFalse Negatives: {fn}\\nTrue Positives: {tp}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Different Models\n",
    "[top](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting number of cvs\n",
    "\n",
    "cv_no = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    7.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: MultinomialNB()\n",
      "\n",
      "Best parameters set: {'alpha': 0.01}\n",
      "\n",
      "train score: 0.7660438667749797\n",
      "test score: 0.6642335766423357\n",
      "\n",
      "Con matrix:\n",
      "\n",
      "True Negatives: 147\n",
      "False Positives: 63\n",
      "False Negatives: 75\n",
      "True Positives: 126\n",
      "\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   31.2s\n",
      "[Parallel(n_jobs=-1)]: Done 160 out of 160 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: KNeighborsClassifier()\n",
      "\n",
      "Best parameters set: {'leaf_size': 1, 'n_neighbors': 2, 'p': 2}\n",
      "\n",
      "train score: 0.6961819658813972\n",
      "test score: 0.5158150851581509\n",
      "\n",
      "Con matrix:\n",
      "\n",
      "True Negatives: 181\n",
      "False Positives: 29\n",
      "False Negatives: 170\n",
      "True Positives: 31\n",
      "\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    8.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RandomForestClassifier()\n",
      "\n",
      "Best parameters set: {'max_depth': 3, 'n_estimators': 200, 'random_state': 42}\n",
      "\n",
      "train score: 0.7676685621445979\n",
      "test score: 0.7055961070559611\n",
      "\n",
      "Con matrix:\n",
      "\n",
      "True Negatives: 148\n",
      "False Positives: 62\n",
      "False Negatives: 59\n",
      "True Positives: 142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for loop to iterate through dictionary of models for testing\n",
    "\n",
    "for clas_name, clas_item in clas_dict.items():   \n",
    "            \n",
    "        # runs a gridsearch on the pipeline using the combined parameters\n",
    "            \n",
    "        gs = GridSearchCV(clas_item, clas_param[clas_name] , cv=cv_no, n_jobs=-1, verbose=2)\n",
    "        gs.fit(X_train, y_train)\n",
    "\n",
    "        # creates a pipeline using the best parameters for the classifier and vectorizer\n",
    "        \n",
    "        optimised = gs.best_estimator_\n",
    "        \n",
    "        # fits, predicts and scores\n",
    "\n",
    "        optimised.fit(X_train, y_train)\n",
    "        \n",
    "        predictions = optimised.predict(X_test)\n",
    "    \n",
    "        train_score = optimised.score(X_train, y_train)\n",
    "        test_score = optimised.score(X_test, y_test)\n",
    "        \n",
    "        # display the results of the optimised fit and the confusion matrix\n",
    "        \n",
    "        print(f'Model: {clas_item}\\n\\nBest parameters set: {gs.best_params_}\\n\\ntrain score: {train_score}\\ntest score: {test_score}\\n\\nCon matrix:\\n')\n",
    "        \n",
    "        con_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Optimisation\n",
    "[top](#Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final model was iteratively further optimized by narrowing down the parameters. While further increases in test scores were possible, the correspondingly high train scores (score > 0.85) showed a large degree of overfitting. A set of parameters were found which managed to maximise the test score while keeping the train score as close to the test score as possible.\n",
    "\n",
    "The final parameters selected were 166 estimators with a max_depth of 2, resulting in a train score of 0.75 and test score of 0.73."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating parameters for final model\n",
    "\n",
    "rf_params = {\n",
    "                'n_estimators': [166],\n",
    "                'max_depth': [2],\n",
    "                'random_state': [random_state]\n",
    "                  }\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RandomForestClassifier()\n",
      "\n",
      "Best parameters set: {'max_depth': 2, 'n_estimators': 166, 'random_state': 42}\n",
      "\n",
      "train score: 0.7457351746547523\n",
      "test score: 0.7274939172749392\n",
      "\n",
      "Con matrix:\n",
      "\n",
      "True Negatives: 154\n",
      "False Positives: 56\n",
      "False Negatives: 56\n",
      "True Positives: 145\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# final model selected\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# GridSearchCV for final model\n",
    "\n",
    "gs = GridSearchCV(rf, rf_params, cv=cv_no, n_jobs=-1, verbose=2)\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "optimized = gs.best_estimator_\n",
    "\n",
    "# fit, predict and score\n",
    "\n",
    "optimized.fit(X_train, y_train)\n",
    "        \n",
    "predictions = optimized.predict(X_test)\n",
    "\n",
    "train_score = optimized.score(X_train, y_train)\n",
    "test_score = optimized.score(X_test, y_test)\n",
    "\n",
    "# display the results of the optimised fit and the confusion matrix\n",
    "\n",
    "print(f'Model: {rf}\\n\\nBest parameters set: {gs.best_params_}\\n\\ntrain score: {train_score}\\ntest score: {test_score}\\n\\nCon matrix:\\n')\n",
    "        \n",
    "con_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "[top](#Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features with the highest importance were extracted from the model and displayed below.\n",
    "\n",
    "Apparent in the features are several themes that significantly factored into causing someone to increase their maliciousness. The words \"Bully\" and it's deriatives, as well as the word \"abuse\" hint that presence of hostile intent from the offending party could cause further escalation. Place of work vs school was also another significant theme, judging by the words \"company\" and \"office\". Finally, there are some words that allude to forward planning in carrying out revenge, e.g. \"plan\" and \"idea\".\n",
    "\n",
    "From this, it can be theorized that an increase in maliciousness can be characterized by 1) the presence of a hostile party, 2) issues in a workplace/school or 3)forward planning.\n",
    "\n",
    "One limitation of this model is the fact that maliciousness is not a binary variable. While the task was to compare only 2 subreddits, it could be argued that creating a \"scale\" of malicousness by using several other \"revenge\" subreddits, such as r/nuclearrevenge or r/maliciouscompliance, would serve to better highlight the nuances in the text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracing Feature Importance\n",
    "[top](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dict = {x:optimized.feature_importances_[i] for i,x in enumerate(X_train)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = pd.DataFrame.from_dict(feature_dict, orient = \"index\")\n",
    "\n",
    "feature_df.rename(columns = {0:\"Importance\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>help</th>\n",
       "      <td>0.054881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bullying</th>\n",
       "      <td>0.031010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>showed</th>\n",
       "      <td>0.029202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>police</th>\n",
       "      <td>0.025817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heard</th>\n",
       "      <td>0.024159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reddit</th>\n",
       "      <td>0.021843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meeting</th>\n",
       "      <td>0.021796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bully</th>\n",
       "      <td>0.021565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expelled</th>\n",
       "      <td>0.020687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idea</th>\n",
       "      <td>0.020685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>video</th>\n",
       "      <td>0.020326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fired</th>\n",
       "      <td>0.019499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bullied</th>\n",
       "      <td>0.019093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plan</th>\n",
       "      <td>0.018471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ground</th>\n",
       "      <td>0.017250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>father</th>\n",
       "      <td>0.016141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relationship</th>\n",
       "      <td>0.014606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self</th>\n",
       "      <td>0.013805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>broke</th>\n",
       "      <td>0.013661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>facebook</th>\n",
       "      <td>0.013338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company</th>\n",
       "      <td>0.012049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>talked</th>\n",
       "      <td>0.011874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>evidence</th>\n",
       "      <td>0.011688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ended</th>\n",
       "      <td>0.011646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <td>0.011080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hole</th>\n",
       "      <td>0.009673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cry</th>\n",
       "      <td>0.009454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>helped</th>\n",
       "      <td>0.009164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>result</th>\n",
       "      <td>0.008704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fake</th>\n",
       "      <td>0.008663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kind</th>\n",
       "      <td>0.007753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>great</th>\n",
       "      <td>0.007671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>involved</th>\n",
       "      <td>0.007370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loved</th>\n",
       "      <td>0.007012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>barely</th>\n",
       "      <td>0.006483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>office</th>\n",
       "      <td>0.006260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worry</th>\n",
       "      <td>0.006010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seriously</th>\n",
       "      <td>0.005810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lived</th>\n",
       "      <td>0.005652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>table</th>\n",
       "      <td>0.005442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address</th>\n",
       "      <td>0.005411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claim</th>\n",
       "      <td>0.005122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caught</th>\n",
       "      <td>0.004999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>town</th>\n",
       "      <td>0.004906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>social</th>\n",
       "      <td>0.004901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cop</th>\n",
       "      <td>0.004901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abuse</th>\n",
       "      <td>0.004786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>laugh</th>\n",
       "      <td>0.004757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huge</th>\n",
       "      <td>0.004751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>message</th>\n",
       "      <td>0.004730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>others</th>\n",
       "      <td>0.004722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experience</th>\n",
       "      <td>0.004621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent</th>\n",
       "      <td>0.004454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>page</th>\n",
       "      <td>0.004373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number</th>\n",
       "      <td>0.004258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>club</th>\n",
       "      <td>0.004208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pushed</th>\n",
       "      <td>0.004187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chat</th>\n",
       "      <td>0.004092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>world</th>\n",
       "      <td>0.003921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>information</th>\n",
       "      <td>0.003805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>began</th>\n",
       "      <td>0.003783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kicked</th>\n",
       "      <td>0.003650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>picture</th>\n",
       "      <td>0.003637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>private</th>\n",
       "      <td>0.003636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>several</th>\n",
       "      <td>0.003624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food</th>\n",
       "      <td>0.003606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mobile</th>\n",
       "      <td>0.003565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lost</th>\n",
       "      <td>0.003558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soon</th>\n",
       "      <td>0.003517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>along</th>\n",
       "      <td>0.003434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>basically</th>\n",
       "      <td>0.003421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>situation</th>\n",
       "      <td>0.003386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>space</th>\n",
       "      <td>0.003384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>real</th>\n",
       "      <td>0.003336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gotten</th>\n",
       "      <td>0.003329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>telling</th>\n",
       "      <td>0.003264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>principal</th>\n",
       "      <td>0.003261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beat</th>\n",
       "      <td>0.003225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recording</th>\n",
       "      <td>0.003073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beginning</th>\n",
       "      <td>0.003027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekend</th>\n",
       "      <td>0.003027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asks</th>\n",
       "      <td>0.002939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contact</th>\n",
       "      <td>0.002934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anger</th>\n",
       "      <td>0.002856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confused</th>\n",
       "      <td>0.002847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mine</th>\n",
       "      <td>0.002811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apparently</th>\n",
       "      <td>0.002745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>felt</th>\n",
       "      <td>0.002645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>read</th>\n",
       "      <td>0.002643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weird</th>\n",
       "      <td>0.002642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>0.002630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forward</th>\n",
       "      <td>0.002617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meet</th>\n",
       "      <td>0.002613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grocery</th>\n",
       "      <td>0.002588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kitchen</th>\n",
       "      <td>0.002511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reported</th>\n",
       "      <td>0.002487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>became</th>\n",
       "      <td>0.002485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seemed</th>\n",
       "      <td>0.002482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poor</th>\n",
       "      <td>0.002479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roommate</th>\n",
       "      <td>0.002476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Importance\n",
       "help            0.054881\n",
       "bullying        0.031010\n",
       "showed          0.029202\n",
       "police          0.025817\n",
       "heard           0.024159\n",
       "reddit          0.021843\n",
       "meeting         0.021796\n",
       "bully           0.021565\n",
       "expelled        0.020687\n",
       "idea            0.020685\n",
       "video           0.020326\n",
       "fired           0.019499\n",
       "bullied         0.019093\n",
       "plan            0.018471\n",
       "ground          0.017250\n",
       "father          0.016141\n",
       "relationship    0.014606\n",
       "self            0.013805\n",
       "broke           0.013661\n",
       "facebook        0.013338\n",
       "company         0.012049\n",
       "talked          0.011874\n",
       "evidence        0.011688\n",
       "ended           0.011646\n",
       "state           0.011080\n",
       "hole            0.009673\n",
       "cry             0.009454\n",
       "helped          0.009164\n",
       "result          0.008704\n",
       "fake            0.008663\n",
       "kind            0.007753\n",
       "great           0.007671\n",
       "involved        0.007370\n",
       "loved           0.007012\n",
       "barely          0.006483\n",
       "office          0.006260\n",
       "worry           0.006010\n",
       "seriously       0.005810\n",
       "lived           0.005652\n",
       "table           0.005442\n",
       "address         0.005411\n",
       "claim           0.005122\n",
       "caught          0.004999\n",
       "town            0.004906\n",
       "social          0.004901\n",
       "cop             0.004901\n",
       "abuse           0.004786\n",
       "laugh           0.004757\n",
       "huge            0.004751\n",
       "message         0.004730\n",
       "others          0.004722\n",
       "experience      0.004621\n",
       "sent            0.004454\n",
       "page            0.004373\n",
       "number          0.004258\n",
       "club            0.004208\n",
       "pushed          0.004187\n",
       "chat            0.004092\n",
       "world           0.003921\n",
       "information     0.003805\n",
       "began           0.003783\n",
       "kicked          0.003650\n",
       "picture         0.003637\n",
       "private         0.003636\n",
       "several         0.003624\n",
       "food            0.003606\n",
       "mobile          0.003565\n",
       "lost            0.003558\n",
       "soon            0.003517\n",
       "along           0.003434\n",
       "basically       0.003421\n",
       "situation       0.003386\n",
       "space           0.003384\n",
       "real            0.003336\n",
       "gotten          0.003329\n",
       "telling         0.003264\n",
       "principal       0.003261\n",
       "beat            0.003225\n",
       "recording       0.003073\n",
       "beginning       0.003027\n",
       "weekend         0.003027\n",
       "asks            0.002939\n",
       "contact         0.002934\n",
       "anger           0.002856\n",
       "confused        0.002847\n",
       "mine            0.002811\n",
       "apparently      0.002745\n",
       "felt            0.002645\n",
       "read            0.002643\n",
       "weird           0.002642\n",
       "text            0.002630\n",
       "forward         0.002617\n",
       "meet            0.002613\n",
       "grocery         0.002588\n",
       "kitchen         0.002511\n",
       "reported        0.002487\n",
       "became          0.002485\n",
       "seemed          0.002482\n",
       "poor            0.002479\n",
       "roommate        0.002476"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_df.sort_values(by = \"Importance\", ascending = False).head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
